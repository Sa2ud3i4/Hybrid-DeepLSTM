{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357bc160-0ae1-40c5-8a0f-01b8f914c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, LSTM, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "#\n",
    "# Load data from CSV file\n",
    "file_path = \"data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the last column is the target variable and all other columns are features\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# Define the number of splits for cross-validation\n",
    "k_folds = 5\n",
    "folds = list(KFold(n_splits=k_folds, shuffle=True).split(X, Y))\n",
    "cvscores = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for j, (train, test) in enumerate(folds):\n",
    "    model = Sequential([\n",
    "        LSTM(128, input_shape=(X.shape[1], 1), return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, kernel_initializer='he_uniform', activation='relu'),\n",
    "        Dense(16, kernel_initializer='he_uniform', activation='relu'),\n",
    "        Dense(8, kernel_initializer='he_uniform', activation='relu'),\n",
    "        Dense(1, kernel_initializer='he_uniform', activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    print('\\nFold =', j)\n",
    "    X_train_cv, y_train_cv = X[train], Y[train]\n",
    "    X_test_cv, y_test_cv = X[test], Y[test]\n",
    "\n",
    "    # Reshape input to be [samples, time steps, features]\n",
    "    X_train_cv = X_train_cv.reshape((X_train_cv.shape[0], X_train_cv.shape[1], 1))\n",
    "    X_test_cv = X_test_cv.reshape((X_test_cv.shape[0], X_test_cv.shape[1], 1))\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(X_train_cv, y_train_cv, epochs=20, batch_size=len(X_train_cv), verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    scores = model.evaluate(X_test_cv, y_test_cv, verbose=0)\n",
    "    print(\"Test Accuracy:\", scores[1] * 100)\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "# Print the mean and standard deviation of the test accuracies\n",
    "print(\"Test Accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ff46a-27c0-479a-a349-52f6ecc976d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the entire training set\n",
    "_, train_acc = model.evaluate(X_train_cv, y_train_cv, verbose=0)\n",
    "print('Train Accuracy: %.2f%%' % (train_acc * 100))\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = (model.predict(X_test_cv) > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test_cv, y_pred))\n",
    "\n",
    "# Confusion matrix and other metrics\n",
    "conf_matrix = confusion_matrix(y_test_cv, y_pred)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "print(\"True Negatives:\", TN)\n",
    "print(\"False Positives:\", FP)\n",
    "print(\"False Negatives:\", FN)\n",
    "print(\"True Positives:\", TP)\n",
    "\n",
    "# Calculate Precision, Recall, F1 Score, MCC, ROC AUC\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "F1_Score = 2 * Precision * Recall / (Precision + Recall)\n",
    "MCC = matthews_corrcoef(y_test_cv, y_pred)\n",
    "ROC_AUC = roc_auc_score(y_test_cv, y_pred)\n",
    "\n",
    "print(\"Precision: {:.2f}\".format(Precision))\n",
    "print(\"Recall: {:.2f}\".format(Recall))\n",
    "print(\"F1 Score: {:.2f}\".format(F1_Score))\n",
    "print(\"MCC: {:.2f}\".format(MCC))\n",
    "print(\"ROC AUC: {:.2f}\".format(ROC_AUC))\n",
    "\n",
    "# Sensitivity and Specificity\n",
    "Sensitivity = Recall  # Same as Recall\n",
    "Specificity = TN / (TN + FP)\n",
    "print(\"Sensitivity: {:.2f}\".format(Sensitivity))\n",
    "print(\"Specificity: {:.2f}\".format(Specificity))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['0', '1'])\n",
    "plt.yticks(tick_marks, ['0', '1'])\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = conf_matrix_normalized.max() / 2.\n",
    "for i, j in itertools.product(range(conf_matrix_normalized.shape[0]), range(conf_matrix_normalized.shape[1])):\n",
    "    plt.text(j, i, format(conf_matrix_normalized[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if conf_matrix_normalized[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss during training\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], linewidth=4)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.grid(True)\n",
    "plt.savefig(r'F:\\other student data\\Abbas\\loss 3.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting accuracy during training\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], linewidth=4)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training Accuracy'])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_cv, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1a97a-76eb-4864-b4c0-6baaf63f99b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
